{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zriTdjauH8iQ"
      },
      "outputs": [],
      "source": [
        "%pip install -q transformers huggingface_hub\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwmTTyjUGqol"
      },
      "source": [
        "### Build-a-transformer\n",
        "\n",
        "In this section, you will implement a transformer language model layer by layer, then use it to generate (hopefully) coherent text.\n",
        "\n",
        "To understand how these layers work, please check out our guide to transformers from [nlp course for you -> transformers](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html#transformer_intro).\n",
        "\n",
        "\n",
        "First, we download pre-trained weights for the [GPT2 model by OpenAI](https://openai.com/research/better-language-models) - a prominent model from 2019.\n",
        "\n",
        "\n",
        "\n",
        "Idea & code by: Ilya Beletsky"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "84e305ce9224488a815b4478db065cf6",
            "049cdbb06f0249a49ee73691cb908788",
            "1cff9e38599f4bdca32cd513bcad75ab",
            "97e030cb4d934d5aad8c85e20d9e368a",
            "c29643aec819458aaded3ac426e87237",
            "674310fa758548c1beb7c359ca83ee7c",
            "2a4506758cd24063ae2bf23c29fc8998",
            "1363cdac2c53450b84bf74e87e486eca",
            "4fd8c23445f84395b65c188c1bdd9ac3",
            "6dc6cd42e6af494c99fc086da0730103",
            "49d9a951e1284a989777683a0b507903"
          ]
        },
        "id": "vOcK0lGTGqol",
        "outputId": "98eff78d-cb26-4ad3-d7e3-648f4938218e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84e305ce9224488a815b4478db065cf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: ['h.0.attn.c_attn.bias', 'h.0.attn.c_attn.weight', 'h.0.attn.c_proj.bias', 'h.0.attn.c_proj.weight', 'h.0.ln_1.bias', 'h.0.ln_1.weight', 'h.0.ln_2.bias', 'h.0.ln_2.weight', 'h.0.mlp.c_fc.bias', 'h.0.mlp.c_fc.weight', 'h.0.mlp.c_proj.bias', 'h.0.mlp.c_proj.weight', 'h.1.attn.c_attn.bias', 'h.1.attn.c_attn.weight', 'h.1. ...\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "state_dict = torch.load(hf_hub_download(\"gpt2\", filename=\"pytorch_model.bin\"))\n",
        "for key, value in tuple(state_dict.items()):\n",
        "    if key.startswith('h.') and key.endswith('.weight') and value.ndim == 2:\n",
        "        value.transpose_(1, 0)  # <-- for compatibility with modern PyTorch modules\n",
        "    if key.startswith('h.') and key.endswith('.attn.bias') and value.ndim == 4:\n",
        "        state_dict.pop(key)  # <-- triangular binar masks, not needed in this code\n",
        "\n",
        "print('Weights:', repr(sorted(state_dict.keys()))[:320], '...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr0SUtQnGqom"
      },
      "source": [
        "In the next few cells, we shall implement the model layer by layer to make use of those weights.\n",
        "\n",
        "As you might recall, transformers contain two main layer types: attention and fully-connected layers.\n",
        "\n",
        "The fully connected layers are by far easier to understand, so we shall begin there:\n",
        "\n",
        "Please implement fully-connected layer __without residual or layer normalization__ (we'll add those in a bit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3Rh-6DX9Gqom"
      },
      "outputs": [],
      "source": [
        "class GeLUThatWasUsedInGPT2(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * x ** 3)))\n",
        "\n",
        "class FullyConnected(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.c_fc = nn.Linear(dim, 4  * dim)\n",
        "        self.gelu = GeLUThatWasUsedInGPT2()\n",
        "        self.c_proj = nn.Linear(4 * dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape = [batch_size, seq_length, dim]\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSVGKnHBGqom"
      },
      "source": [
        "Now, let's test that it works with GPT-2 weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CoWjZwZkGqom",
        "outputId": "c3979b3c-9162-428a-f492-9b5f21f495d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems legit!\n"
          ]
        }
      ],
      "source": [
        "mlp = FullyConnected(dim=768)\n",
        "mlp.load_state_dict({'c_fc.weight': state_dict['h.0.mlp.c_fc.weight'],\n",
        "                     'c_fc.bias': state_dict['h.0.mlp.c_fc.bias'],\n",
        "                     'c_proj.weight': state_dict['h.0.mlp.c_proj.weight'],\n",
        "                     'c_proj.bias': state_dict['h.0.mlp.c_proj.bias']})\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "x = torch.randn(1, 2, 768)  # [batch_size, sequence_length, dim]\n",
        "checksum = torch.sum(mlp(x) * x)\n",
        "assert abs(checksum.item() - 1282.3315) < 0.1, \"layer outputs do not match reference\"\n",
        "assert torch.allclose(mlp(x[:, (1, 0), :])[:, (1, 0), :], mlp(x)), \"mlp must be permutation-invariant\"\n",
        "print(\"Seems legit!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbfCevRwGqom"
      },
      "source": [
        "Now, let's get to attention layers.\n",
        "\n",
        "Since GPT-2 needs to generate text from left to right, each generated token can only attend to tokens on the left (and itself). This kid of attention is called \"Masked\" self-attention, because it hides tokens to the right.\n",
        "\n",
        "As before, please implement masked self-attention __without layernorm or residual connections.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T6j7M4hLGqon"
      },
      "outputs": [],
      "source": [
        "# class MaskedSelfAttention(nn.Module):\n",
        "#     def __init__(self, dim: int, num_heads: int):\n",
        "#         super().__init__()\n",
        "#         self.c_attn = nn.Linear(dim, dim * 3)  # query + key + value, combined\n",
        "#         self.c_proj = nn.Linear(dim, dim)  # output projection\n",
        "#         self.dim, self.num_heads = dim, num_heads\n",
        "#         self.head_size = dim // num_heads\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         q, k, v = self.c_attn(x).split(dim=-1, split_size=self.dim)\n",
        "#         assert q.shape == k.shape == v.shape == x.shape, \"q, k and v must have the same shape as x\"\n",
        "\n",
        "\n",
        "#         # Note: this is an inefficient implementation that uses a for-loop.\n",
        "#         # To get the full grade during homework, please re-implement this code:\n",
        "#         # 1) do not use for-loops (or other loops). Compute everything in parallel with vectorized operations\n",
        "#         # 2) do not use F.scaled_dot_product_attention - write your own attention code using basic PyTorch ops\n",
        "#         head_outputs = []\n",
        "#         for head_index in range(self.num_heads):\n",
        "#             head_selector = range(self.head_size * head_index, self.head_size * (head_index + 1))\n",
        "\n",
        "#             head_queries = q[..., head_selector]\n",
        "#             head_keys = k[..., head_selector]\n",
        "#             head_values = v[..., head_selector]\n",
        "\n",
        "#             single_head_output = F.scaled_dot_product_attention(\n",
        "#                 query=head_queries,\n",
        "#                 key=head_keys,\n",
        "#                 value=head_values,\n",
        "#                 attn_mask=None,\n",
        "#                 dropout_p=0.0,\n",
        "#                 # <YOUR CODE HERE - fill in the missing parameters; see docs below>\n",
        "#                 is_causal=True)\n",
        "#             # docs: https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "#             head_outputs.append(single_head_output)\n",
        "\n",
        "#         combined_head_outputs = torch.cat(head_outputs, dim=-1)\n",
        "#         return self.c_proj(combined_head_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedSelfAttention(nn.Module):\n",
        "    def __init__(self, dim: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.c_attn = nn.Linear(dim, dim * 3)  # query + key + value, combined\n",
        "        self.c_proj = nn.Linear(dim, dim)   # output projection\n",
        "        self.dim, self.num_heads = dim, num_heads\n",
        "        self.head_size = dim // num_heads\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        assert C == self.dim\n",
        "        q, k, v = self.c_attn(x).split(self.dim, dim=-1)\n",
        "        q = q.view(B, T, self.num_heads, self.head_size).transpose(1, 2)\n",
        "        k = k.view(B, T, self.num_heads, self.head_size).transpose(1, 2)\n",
        "        v = v.view(B, T, self.num_heads, self.head_size).transpose(1, 2)\n",
        "\n",
        "        scale = 1.0 / math.sqrt(self.head_size)\n",
        "        attention_scores = torch.matmul(q, k.transpose(-2, -1)) * scale\n",
        "\n",
        "        mask = torch.tril(torch.ones(T, T, device=x.device))\n",
        "        attention_scores = attention_scores.masked_fill(mask == 0, float('-inf'))\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "        attention_output = torch.matmul(attention_weights, v)\n",
        "        attention_output = attention_output.transpose(1, 2).contiguous()\n",
        "        attention_output = attention_output.view(B, T, C)\n",
        "\n",
        "        return self.c_proj(attention_output)\n"
      ],
      "metadata": {
        "id": "0fVs__ErGpd2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umZpcpIkJva7"
      },
      "source": [
        "Test that it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg5Oj_PPM6hj",
        "outputId": "29e64792-1b0f-4744-b5ee-81f887406c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It works!\n"
          ]
        }
      ],
      "source": [
        "attn = MaskedSelfAttention(dim=768, num_heads=12)\n",
        "attn.load_state_dict({'c_attn.weight': state_dict['h.0.attn.c_attn.weight'],\n",
        "                      'c_attn.bias': state_dict['h.0.attn.c_attn.bias'],\n",
        "                      'c_proj.weight': state_dict['h.0.attn.c_proj.weight'],\n",
        "                      'c_proj.bias': state_dict['h.0.attn.c_proj.bias']})\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "x = torch.randn(1, 10, 768)  # [batch_size, sequence_length, dim]\n",
        "checksum = torch.sum(attn(x) * x)\n",
        "assert abs(checksum.item() - 2703.6772) < 0.1, \"layer outputs do not match reference\"\n",
        "assert not torch.allclose(attn(x[:, (1, 0), :])[:, (1, 0), :], attn(x[:, (0, 1), :])), \"masked attention must *not* be permutation-invariant\"\n",
        "print(\"It works!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn6tgTHzOK4l"
      },
      "source": [
        "We can now combine attention and MLP to build the full transformer layer:\n",
        "\n",
        "![img](https://i.imgur.com/1sq2vHO.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p3AH7YQvRpvU"
      },
      "outputs": [],
      "source": [
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self, dim: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(dim)\n",
        "        self.attn = MaskedSelfAttention(dim, num_heads)\n",
        "        self.ln_2 = nn.LayerNorm(dim)\n",
        "        self.mlp = FullyConnected(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "        # <YOUR CODE - apply attention, mlp and layer normalization as shown in figure above>\n",
        "        # return <...>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzo_QeFVSNZa",
        "outputId": "ed836121-44bc-4d14-fb26-301c556ab5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good job!\n"
          ]
        }
      ],
      "source": [
        "layer = TransformerLayer(dim=768, num_heads=12)\n",
        "layer.load_state_dict({k[5:]: v for k, v in state_dict.items() if k.startswith('h.10.')})\n",
        "assert abs(torch.sum(layer(x) * x).item() - 9874.7383) < 0.1\n",
        "print(\"Good job!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Mbqw9iuaSrYy"
      },
      "outputs": [],
      "source": [
        "class GPT2(nn.Module):\n",
        "    def __init__(self, vocab_size: int, dim: int, num_heads: int, num_layers: int, max_position_embeddings: int = 1024):\n",
        "        super().__init__()\n",
        "        self.wte = nn.Embedding(vocab_size, dim)  # token embeddings\n",
        "        self.wpe = nn.Embedding(max_position_embeddings, dim)  # position embeddings\n",
        "        self.ln_f = nn.LayerNorm(dim)   # final layer norm - goes after all transformer layers, but before logits\n",
        "\n",
        "        self.h = nn.Sequential(*(TransformerLayer(dim, num_heads) for layer in range(num_layers)))\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # input_ids.shape: [batch_size, sequence_length], int64 token ids\n",
        "        position_ids = torch.arange(input_ids.shape[1], device=input_ids.device).unsqueeze(0)\n",
        "\n",
        "        token_embeddings = self.wte(input_ids)\n",
        "        position_embeddings = self.wpe(position_ids)\n",
        "        full_embeddings = token_embeddings + position_embeddings\n",
        "\n",
        "        transformer_output = self.h(full_embeddings)\n",
        "        transformer_output_ln = self.ln_f(transformer_output)\n",
        "\n",
        "        # final layer: we predict logits by re-using token embeddings as linear weights\n",
        "        output_logits = transformer_output_ln @ self.wte.weight.T\n",
        "        return output_logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p0m8jt66aDIh",
        "outputId": "7d653523-1740-417d-dd72-bf8d69f0d818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  look\n"
          ]
        }
      ],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2', add_prefix_space=True)\n",
        "model = GPT2(vocab_size=50257, dim=768, num_heads=12, num_layers=12)\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "input_ids = tokenizer(\"A quick\", return_tensors='pt')['input_ids']\n",
        "\n",
        "predicted_logits = model(input_ids)\n",
        "most_likely_token_id = predicted_logits[:, -1].argmax().item()\n",
        "\n",
        "print(\"Prediction:\", tokenizer.decode(most_likely_token_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8ql3Lo7dXZ2",
        "outputId": "c450bda6-9f0f-413f-e936-01ae34e23631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Fermi paradox  is very much an object in itself, but it travels an undetermined path by postulating a spectrum. When\n",
            " folded into a boxaway subspace never found in atop our host planet , being entangled in box  only completes a treadmill-\n",
            "like trance and spasm off into space later to smoke cigarettes and screed at the moon sometime to carry out A.E. Muslim delusions\n",
            " about Islam. The monkey that quakes a Tokyo earthquake anything is its flying monkey: and that only tangentially related\n",
            " to the paved surface hull of Tokyo Munto.  IRL John Shuttle\n",
            "Breakause is Not Dark, it's Open Source.\n",
            "Cross translations of\n",
            " some of Jeff's lectures handed out \n",
            "Get your fingerprints cleaned. Imagine Microbiologia (ingredients direct from the patient\n",
            "'s blood, used for antiviral agents, enzymes) taking the Chinese words \"serotonin\" and turning them into Surface Neurolog\n",
            "ical Disease   can yield an extraordinarily shocking result: A clinically reliable CD3+ Toxoplasma gondii, which forms oscill\n",
            "ating crystals in organelles, nuclei, and tissues. In a nod to the futuristic B  G Pei project, Gene Karp states that the\n",
            " of space radiologist Paul Devey seeks and develops clinical tools and brand of vaccine with the Hakuya curse, after Morse\n",
            " Code (actually basic Deep Consciousness testing that headlines the sci fi HBO series A New Hope at Fr.....eager yet rewarding\n",
            " ne quiet.\")\n",
            "Vox physics (@pezmoments  at Vic_Dain FiiF WT Stalin 86 Under Construction Launch Projects demolition & build\n",
            "-it-usa torus tweet 1024 updates Li���ng juni 2017  500 and/or 1,000 Indniverse Day sequences shared  today at past festivals\n",
            " using VMP messages from Moses Mhosa's critical blog. This visualization of vision and curvature even imagines a glimpse at\n",
            " the alien race: apparently Narendi \"The Ruler of Optics\" Eightsaber is about to show-off some breakthrough surgery he was\n",
            " regularly used to heal wounds. Image via Alexander Popui. On the open sky wind  outside 08 am (Sov cancels for a few minutes\n",
            " of uploading @ plyinghub sounds like amateur singers who're using mutual masturbation sessions), auras are varying levels\n",
            " of astral projection:  democratic movements, such as Bohemian Spring, are possible. A sensual outing 96 . Rosen under review\n",
            " - volume 101"
          ]
        }
      ],
      "source": [
        "text = \"The Fermi paradox \"\n",
        "tokens = tokenizer.encode(text)\n",
        "print(end=tokenizer.decode(tokens))\n",
        "line_length = len(tokenizer.decode(tokens))\n",
        "\n",
        "for i in range(500):\n",
        "    # Predict logits with your model\n",
        "    with torch.no_grad():\n",
        "        logits = model(torch.as_tensor([tokens]))\n",
        "\n",
        "    # Sample with probabilities\n",
        "    p_next = torch.softmax(logits[0, -1, :], dim=-1).data.cpu().numpy()\n",
        "    next_token_index = np.random.choice(len(p_next), p=p_next)\n",
        "\n",
        "    tokens.append(int(next_token_index))\n",
        "    print(end=tokenizer.decode(tokens[-1]))\n",
        "    line_length += len(tokenizer.decode(tokens[-1]))\n",
        "    if line_length > 120:\n",
        "      line_length = 0\n",
        "      print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3NJ0ocgGqop"
      },
      "source": [
        "__Reminder:__ after class, please go to `MaskedSelfAttention.forward` above and finish the job!\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "### Here's how you can do the same with transformers library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NTOHu124Gqop",
        "outputId": "61d9d801-a098-4641-c0b3-43eff3ea80ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "b3c80eae728f4fc49f6051fcd9bf391f",
            "35affeef85374049aec90fc8c656477c",
            "6c0015452c4447ddbd96a1d40c6c87f1",
            "b495ed4367cc4f3e873eace9be46c216",
            "7a010b409ca741c5985ca42269b94a30",
            "94dd57994939486994c27f1a1f8767b3",
            "ababbb09bcc94f289203fdda9387c439",
            "337cbee173324beebf23c45eeb017f68",
            "ac05bf1916eb44de8bed5a3b8886b2ac",
            "9327abb32cc74db6a82814d4751748bc",
            "35f5a81543194bcb8991e0686ed9dca5",
            "423b726b4c9e46668dda022e258d15b1",
            "622cc23b08024eabbdf5b6af402c292a",
            "e684e6d0904f40a9a2515fd011bb3297",
            "eecc98c09ae84844ab2f8d9b24825f81",
            "4c6e907f457e431da9efa4aaf9c9232a",
            "aa88dad116324395a3bf2bde9136ad28",
            "d8c73e681dff4a3082c7820dcc16f906",
            "460b83b4a5c84a0c92d2e214a5a05992",
            "71402448606a48098761be896d0ef2a3",
            "5887fd6a547441bf9389354a2c649400",
            "df2ddfc97a1b44059f38f800d34772e2"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3c80eae728f4fc49f6051fcd9bf391f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "423b726b4c9e46668dda022e258d15b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:  The Fermi paradox  in physics makes clear that if I am to know whether a particle \\(Q\\) has an identity with a neighboring particle \\(R_{\\alpha}\\) by the equation π \\(a\\) where R is of the form: \\(Q\\) is\n"
          ]
        }
      ],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2', add_prefix_space=True)\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "print('Generated text:', tokenizer.decode(\n",
        "    model.generate(\n",
        "        **tokenizer(\"The Fermi paradox \", return_tensors='pt'),\n",
        "        do_sample=True, max_new_tokens=50\n",
        "    ).flatten().numpy()\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OnaXvlImGU7R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py38",
      "language": "python",
      "name": "py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84e305ce9224488a815b4478db065cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_049cdbb06f0249a49ee73691cb908788",
              "IPY_MODEL_1cff9e38599f4bdca32cd513bcad75ab",
              "IPY_MODEL_97e030cb4d934d5aad8c85e20d9e368a"
            ],
            "layout": "IPY_MODEL_c29643aec819458aaded3ac426e87237"
          }
        },
        "049cdbb06f0249a49ee73691cb908788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_674310fa758548c1beb7c359ca83ee7c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a4506758cd24063ae2bf23c29fc8998",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "1cff9e38599f4bdca32cd513bcad75ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1363cdac2c53450b84bf74e87e486eca",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fd8c23445f84395b65c188c1bdd9ac3",
            "value": 548118077
          }
        },
        "97e030cb4d934d5aad8c85e20d9e368a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dc6cd42e6af494c99fc086da0730103",
            "placeholder": "​",
            "style": "IPY_MODEL_49d9a951e1284a989777683a0b507903",
            "value": " 548M/548M [00:08&lt;00:00, 64.4MB/s]"
          }
        },
        "c29643aec819458aaded3ac426e87237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674310fa758548c1beb7c359ca83ee7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4506758cd24063ae2bf23c29fc8998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1363cdac2c53450b84bf74e87e486eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd8c23445f84395b65c188c1bdd9ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dc6cd42e6af494c99fc086da0730103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d9a951e1284a989777683a0b507903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3c80eae728f4fc49f6051fcd9bf391f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35affeef85374049aec90fc8c656477c",
              "IPY_MODEL_6c0015452c4447ddbd96a1d40c6c87f1",
              "IPY_MODEL_b495ed4367cc4f3e873eace9be46c216"
            ],
            "layout": "IPY_MODEL_7a010b409ca741c5985ca42269b94a30"
          }
        },
        "35affeef85374049aec90fc8c656477c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94dd57994939486994c27f1a1f8767b3",
            "placeholder": "​",
            "style": "IPY_MODEL_ababbb09bcc94f289203fdda9387c439",
            "value": "model.safetensors: 100%"
          }
        },
        "6c0015452c4447ddbd96a1d40c6c87f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337cbee173324beebf23c45eeb017f68",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac05bf1916eb44de8bed5a3b8886b2ac",
            "value": 548105171
          }
        },
        "b495ed4367cc4f3e873eace9be46c216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9327abb32cc74db6a82814d4751748bc",
            "placeholder": "​",
            "style": "IPY_MODEL_35f5a81543194bcb8991e0686ed9dca5",
            "value": " 548M/548M [00:06&lt;00:00, 72.5MB/s]"
          }
        },
        "7a010b409ca741c5985ca42269b94a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94dd57994939486994c27f1a1f8767b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ababbb09bcc94f289203fdda9387c439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "337cbee173324beebf23c45eeb017f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac05bf1916eb44de8bed5a3b8886b2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9327abb32cc74db6a82814d4751748bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f5a81543194bcb8991e0686ed9dca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "423b726b4c9e46668dda022e258d15b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_622cc23b08024eabbdf5b6af402c292a",
              "IPY_MODEL_e684e6d0904f40a9a2515fd011bb3297",
              "IPY_MODEL_eecc98c09ae84844ab2f8d9b24825f81"
            ],
            "layout": "IPY_MODEL_4c6e907f457e431da9efa4aaf9c9232a"
          }
        },
        "622cc23b08024eabbdf5b6af402c292a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa88dad116324395a3bf2bde9136ad28",
            "placeholder": "​",
            "style": "IPY_MODEL_d8c73e681dff4a3082c7820dcc16f906",
            "value": "generation_config.json: 100%"
          }
        },
        "e684e6d0904f40a9a2515fd011bb3297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_460b83b4a5c84a0c92d2e214a5a05992",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71402448606a48098761be896d0ef2a3",
            "value": 124
          }
        },
        "eecc98c09ae84844ab2f8d9b24825f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5887fd6a547441bf9389354a2c649400",
            "placeholder": "​",
            "style": "IPY_MODEL_df2ddfc97a1b44059f38f800d34772e2",
            "value": " 124/124 [00:00&lt;00:00, 13.9kB/s]"
          }
        },
        "4c6e907f457e431da9efa4aaf9c9232a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa88dad116324395a3bf2bde9136ad28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c73e681dff4a3082c7820dcc16f906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "460b83b4a5c84a0c92d2e214a5a05992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71402448606a48098761be896d0ef2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5887fd6a547441bf9389354a2c649400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2ddfc97a1b44059f38f800d34772e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}